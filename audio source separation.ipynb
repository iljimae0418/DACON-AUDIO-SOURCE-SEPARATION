{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References \n",
    "- https://medium.com/@keur.plkar/audio-data-augmentation-in-python-a91600613e47 \n",
    "- https://dacon.io/competitions/official/235616/codeshare/1295?page=1&dtype=recent&ptype=pub  \n",
    "- https://dacon.io/competitions/official/235616/codeshare/1340?page=1&dtype=recent&ptype=pub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install keras and other necessary packages before importing\n",
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy\n",
    "from scipy import signal\n",
    "import tensorflow as tf  \n",
    "import keras \n",
    "from tqdm import tqdm \n",
    "from glob import glob \n",
    "from scipy.io import wavfile \n",
    "from keras import Input, Model\n",
    "from keras.models import Sequential, load_model \n",
    "from keras.layers import Dense, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, AveragePooling2D, Flatten, BatchNormalization, Dropout, LeakyReLU, Deconv2D, Activation, Concatenate, Add\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping \n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation class \n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, list_IDs, labels, batch_size, dim, n_channels, n_classes, shuffle = True):\n",
    "        self.dim = dim\n",
    "        self.batch_size = batch_size\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    # number of batches every epoch\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
    "\n",
    "    # generate the actual batch data\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size : (index+1) * self.batch_size]\n",
    "        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "        return X, y\n",
    "\n",
    "    # shuffles indices after every epoch\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.list_IDs))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        # Initialization\n",
    "        X = np.empty((self.batch_size, *self.dim, self.n_channels))\n",
    "        \n",
    "        y = np.empty((self.batch_size, 30)) # we have 30 labels \n",
    "    \n",
    "        \n",
    "        # Generate data\n",
    "        for i, ID in enumerate(list_IDs_temp):\n",
    "            # Store sample\n",
    "            X[i,] = np.load('./storage/train_augmented/' + ID) \n",
    "\n",
    "            # Store class\n",
    "            y[i,] = self.labels[ID] \n",
    "   \n",
    "        return X, y \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(files): \n",
    "    out = [] \n",
    "    for file in tqdm(files): \n",
    "        fs, data = wavfile.read(file) \n",
    "        out.append(data) \n",
    "    out = np.array(out) \n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an alternative would be to use the melspectrogram provided by the librosa library \n",
    "def log_specgram(audio, sample_rate, window_size = 20, step_size = 10, eps=1e-10): \n",
    "    nperseg = int(round(window_size * sample_rate / 1e3)) \n",
    "    noverlap = int(round(step_size * sample_rate / 1e3)) \n",
    "    freqs, times, spec = signal.spectrogram(audio, \n",
    "                                           fs=sample_rate, \n",
    "                                           window='hann',\n",
    "                                           nperseg=nperseg,\n",
    "                                           noverlap=noverlap,\n",
    "                                           detrend=False) \n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs to be run one time only \n",
    "# saves spectrogram data after normalizing \n",
    "# also does data augmentation to training data, and the data size increases from 100,000 to 400,000 \n",
    "def save_spectrogram(files):  \n",
    "    for file in tqdm(files):   \n",
    "        sample, sample_rate = librosa.load(file) \n",
    "        freqs, times, spectrogram = log_specgram(sample, sample_rate) \n",
    "        mean = np.mean(spectrogram, axis=0) \n",
    "        std = np.std(spectrogram, axis = 0)\n",
    "        spectrogram = (spectrogram - mean)/std  \n",
    "        spectrogram = spectrogram.reshape((spectrogram.shape[0],spectrogram.shape[1],1)) \n",
    "        np.save('./storage/train_augmented/' + file[28:] + \"_original\", spectrogram) \n",
    "        \n",
    "        # add noise \n",
    "        sample_noise = sample + np.random.uniform(0.005,0.5) * np.random.normal(0,1,len(sample)) \n",
    "        freqs, times, spectrogram_noise = log_specgram(sample_noise, sample_rate)\n",
    "        mean = np.mean(spectrogram_noise, axis=0) \n",
    "        std = np.std(spectrogram_noise, axis = 0)\n",
    "        spectrogram_noise = (spectrogram_noise - mean)/std  \n",
    "        spectrogram_noise = spectrogram_noise.reshape((spectrogram_noise.shape[0],spectrogram_noise.shape[1],1)) \n",
    "        np.save('./storage/train_augmented/' + file[28:] + \"_noised\", spectrogram_noise)\n",
    "        \n",
    "        # add shift \n",
    "        sample_shift = np.roll(sample, int(sample_rate/10)) \n",
    "        freqs, times, spectrogram_shift = log_specgram(sample_shift, sample_rate) \n",
    "        mean = np.mean(spectrogram_shift, axis=0) \n",
    "        std = np.std(spectrogram_shift, axis = 0)\n",
    "        spectrogram_shift = (spectrogram_shift - mean)/std  \n",
    "        spectrogram_shift = spectrogram_shift.reshape((spectrogram_shift.shape[0],spectrogram_shift.shape[1],1))\n",
    "        np.save('./storage/train_augmented/' + file[28:] + \"_shifted\", spectrogram_shift) \n",
    "        \n",
    "        # add pitch shift \n",
    "        sample_pitch_shift = librosa.effects.pitch_shift(sample, sample_rate, n_steps = np.random.randint(-5,5)) \n",
    "        freqs, times, spectrogram_pitch_shift = log_specgram(sample_pitch_shift, sample_rate) \n",
    "        mean = np.mean(spectrogram_pitch_shift, axis=0) \n",
    "        std = np.std(spectrogram_pitch_shift, axis = 0)\n",
    "        spectrogram_pitch_shift = (spectrogram_pitch_shift - mean)/std  \n",
    "        spectrogram_pitch_shift = spectrogram_pitch_shift.reshape((spectrogram_pitch_shift.shape[0],spectrogram_pitch_shift.shape[1],1))\n",
    "        np.save('./storage/train_augmented/' + file[28:] + \"_pitch_shifted\", spectrogram_pitch_shift) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:44<00:00,  6.07it/s]\n",
      "100%|██████████| 1000/1000 [02:56<00:00,  5.68it/s]\n",
      "100%|██████████| 1000/1000 [02:43<00:00,  6.10it/s]\n",
      "100%|██████████| 1000/1000 [04:14<00:00,  3.93it/s]\n",
      "100%|██████████| 1000/1000 [04:05<00:00,  4.07it/s]\n",
      "100%|██████████| 1000/1000 [02:56<00:00,  5.67it/s]\n",
      "100%|██████████| 1000/1000 [02:52<00:00,  5.81it/s]\n",
      "100%|██████████| 1000/1000 [02:45<00:00,  6.04it/s]\n",
      "100%|██████████| 1000/1000 [02:45<00:00,  6.05it/s]\n",
      "100%|██████████| 1000/1000 [02:57<00:00,  5.63it/s]\n",
      "100%|██████████| 1000/1000 [02:50<00:00,  5.86it/s]\n",
      "100%|██████████| 1000/1000 [03:08<00:00,  5.30it/s]\n",
      "100%|██████████| 1000/1000 [02:51<00:00,  5.82it/s]\n",
      "100%|██████████| 1000/1000 [02:45<00:00,  6.03it/s]\n",
      "100%|██████████| 1000/1000 [02:47<00:00,  5.98it/s]\n",
      "100%|██████████| 1000/1000 [02:46<00:00,  6.02it/s]\n",
      "100%|██████████| 1000/1000 [02:41<00:00,  6.17it/s]\n",
      "100%|██████████| 1000/1000 [02:42<00:00,  6.14it/s]\n",
      "100%|██████████| 1000/1000 [02:42<00:00,  6.14it/s]\n",
      "100%|██████████| 1000/1000 [02:40<00:00,  6.24it/s]\n",
      "100%|██████████| 1000/1000 [02:45<00:00,  6.05it/s]\n",
      "100%|██████████| 1000/1000 [02:50<00:00,  5.85it/s]\n",
      "100%|██████████| 1000/1000 [02:44<00:00,  6.07it/s]\n",
      "100%|██████████| 1000/1000 [02:50<00:00,  5.88it/s]\n",
      "100%|██████████| 1000/1000 [03:03<00:00,  5.45it/s]\n",
      "100%|██████████| 1000/1000 [02:59<00:00,  5.57it/s]\n",
      "100%|██████████| 1000/1000 [03:04<00:00,  5.43it/s]\n",
      "100%|██████████| 1000/1000 [02:57<00:00,  5.63it/s]\n",
      "100%|██████████| 1000/1000 [03:01<00:00,  5.52it/s]\n",
      "100%|██████████| 1000/1000 [03:00<00:00,  5.53it/s]\n",
      "100%|██████████| 1000/1000 [02:54<00:00,  5.74it/s]\n",
      "100%|██████████| 1000/1000 [02:44<00:00,  6.08it/s]\n",
      "100%|██████████| 1000/1000 [02:45<00:00,  6.04it/s]\n",
      "100%|██████████| 1000/1000 [02:44<00:00,  6.08it/s]\n",
      "100%|██████████| 1000/1000 [02:43<00:00,  6.12it/s]\n",
      "100%|██████████| 1000/1000 [02:43<00:00,  6.12it/s]\n",
      "100%|██████████| 1000/1000 [02:46<00:00,  6.01it/s]\n",
      "100%|██████████| 1000/1000 [02:46<00:00,  6.02it/s]\n",
      "100%|██████████| 1000/1000 [02:44<00:00,  6.09it/s]\n",
      "100%|██████████| 1000/1000 [02:43<00:00,  6.11it/s]\n",
      "100%|██████████| 1000/1000 [02:43<00:00,  6.11it/s]\n",
      "100%|██████████| 1000/1000 [02:46<00:00,  5.99it/s]\n",
      "100%|██████████| 1000/1000 [02:45<00:00,  6.04it/s]\n",
      "100%|██████████| 1000/1000 [02:45<00:00,  6.04it/s]\n",
      "100%|██████████| 1000/1000 [02:44<00:00,  6.08it/s]\n",
      "100%|██████████| 1000/1000 [02:45<00:00,  6.03it/s]\n",
      "100%|██████████| 1000/1000 [02:44<00:00,  6.07it/s]\n",
      "100%|██████████| 1000/1000 [02:43<00:00,  6.11it/s]\n",
      "100%|██████████| 1000/1000 [02:45<00:00,  6.06it/s]\n",
      "100%|██████████| 1000/1000 [02:44<00:00,  6.06it/s]\n",
      "100%|██████████| 1000/1000 [02:49<00:00,  5.91it/s]\n",
      "100%|██████████| 1000/1000 [02:47<00:00,  5.95it/s]\n",
      "100%|██████████| 1000/1000 [02:46<00:00,  6.02it/s]\n",
      "100%|██████████| 1000/1000 [03:04<00:00,  5.43it/s] \n",
      "100%|██████████| 1000/1000 [03:05<00:00,  5.38it/s]\n",
      "100%|██████████| 1000/1000 [02:47<00:00,  5.97it/s]\n",
      "100%|██████████| 1000/1000 [02:48<00:00,  5.95it/s]\n",
      "100%|██████████| 1000/1000 [02:49<00:00,  5.90it/s]\n",
      "100%|██████████| 1000/1000 [02:49<00:00,  5.91it/s]\n",
      "100%|██████████| 1000/1000 [02:51<00:00,  5.83it/s]\n",
      "100%|██████████| 1000/1000 [02:48<00:00,  5.92it/s]\n",
      "100%|██████████| 1000/1000 [02:49<00:00,  5.89it/s]\n",
      "100%|██████████| 1000/1000 [02:48<00:00,  5.94it/s]\n",
      "100%|██████████| 1000/1000 [02:49<00:00,  5.89it/s]\n",
      "100%|██████████| 1000/1000 [02:49<00:00,  5.92it/s]\n",
      "100%|██████████| 1000/1000 [02:41<00:00,  6.18it/s]\n",
      "100%|██████████| 1000/1000 [02:35<00:00,  6.44it/s]\n",
      "100%|██████████| 1000/1000 [02:36<00:00,  6.41it/s]\n",
      "100%|██████████| 1000/1000 [02:36<00:00,  6.37it/s]\n",
      "100%|██████████| 1000/1000 [02:37<00:00,  6.33it/s]\n",
      "100%|██████████| 1000/1000 [02:36<00:00,  6.38it/s]\n",
      "100%|██████████| 1000/1000 [02:34<00:00,  6.49it/s]\n",
      "100%|██████████| 1000/1000 [02:35<00:00,  6.42it/s]\n",
      "100%|██████████| 1000/1000 [02:34<00:00,  6.47it/s]\n",
      "100%|██████████| 1000/1000 [02:35<00:00,  6.43it/s]\n",
      "100%|██████████| 1000/1000 [02:34<00:00,  6.46it/s]\n",
      "100%|██████████| 1000/1000 [02:32<00:00,  6.56it/s]\n",
      "100%|██████████| 1000/1000 [02:35<00:00,  6.43it/s]\n",
      "100%|██████████| 1000/1000 [02:36<00:00,  6.38it/s]\n",
      "100%|██████████| 1000/1000 [02:34<00:00,  6.49it/s]\n",
      "100%|██████████| 1000/1000 [02:32<00:00,  6.55it/s]\n",
      "100%|██████████| 1000/1000 [02:33<00:00,  6.52it/s]\n",
      "100%|██████████| 1000/1000 [02:33<00:00,  6.49it/s]\n",
      "100%|██████████| 1000/1000 [02:34<00:00,  6.47it/s]\n",
      "100%|██████████| 1000/1000 [02:33<00:00,  6.50it/s]\n",
      "100%|██████████| 1000/1000 [02:33<00:00,  6.52it/s]\n",
      "100%|██████████| 1000/1000 [02:34<00:00,  6.49it/s]\n",
      "100%|██████████| 1000/1000 [02:35<00:00,  6.42it/s]\n",
      "100%|██████████| 1000/1000 [02:36<00:00,  6.38it/s]\n",
      "100%|██████████| 1000/1000 [02:37<00:00,  6.35it/s]\n",
      "100%|██████████| 1000/1000 [02:47<00:00,  5.95it/s]\n",
      "100%|██████████| 1000/1000 [02:37<00:00,  6.36it/s]\n",
      "100%|██████████| 1000/1000 [02:37<00:00,  6.33it/s]\n",
      "100%|██████████| 1000/1000 [02:35<00:00,  6.43it/s]\n",
      "100%|██████████| 1000/1000 [02:36<00:00,  6.41it/s]\n",
      "100%|██████████| 1000/1000 [02:36<00:00,  6.38it/s]\n",
      "100%|██████████| 1000/1000 [02:35<00:00,  6.43it/s]\n",
      "100%|██████████| 1000/1000 [02:43<00:00,  6.12it/s]\n",
      "100%|██████████| 1000/1000 [02:41<00:00,  6.20it/s]\n",
      "100%|██████████| 1000/1000 [02:37<00:00,  6.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# save processed numpy file to persistent storage. \n",
    "# needs to be run only once \n",
    "x_data = [os.path.join('./storage/train_files/train',file) for file in os.listdir('./storage/train_files/train')]   \n",
    "x_data.sort()  \n",
    "for i in range(0,len(x_data),1000): \n",
    "    save_spectrogram(x_data[i:i+1000])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = pd.read_csv('./storage/train_answer.csv', index_col=0) \n",
    "y_data = y_data.values\n",
    "y_data_augmented = [] \n",
    "for ans in y_data: \n",
    "    for i in range(4): \n",
    "        y_data_augmented.append(ans) \n",
    "        \n",
    "        \n",
    "y_data_augmented = np.asarray(y_data_augmented) \n",
    "y_data_augmented.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_00000.wav_noised.npy', 'train_00000.wav_original.npy', 'train_00000.wav_pitch_shifted.npy', 'train_00000.wav_shifted.npy', 'train_00001.wav_noised.npy', 'train_00001.wav_original.npy', 'train_00001.wav_pitch_shifted.npy', 'train_00001.wav_shifted.npy', 'train_00002.wav_noised.npy', 'train_00002.wav_original.npy']\n"
     ]
    }
   ],
   "source": [
    "# read in x_data \n",
    "filepath = './storage/train_augmented/'\n",
    "x_data = [file for file in os.listdir(filepath)] \n",
    "x_data.sort() \n",
    "print(x_data[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320000, 80000, (320000, 30), (80000, 30))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters\n",
    "params = {'dim': (98, 221),\n",
    "          'batch_size': 256,\n",
    "          'n_classes': 30,\n",
    "          'n_channels': 1,\n",
    "          'shuffle': True}\n",
    "\n",
    "partition = {'train':[] , 'validation':[]} \n",
    "labels = {} \n",
    "\n",
    "k = int(0.8*len(x_data)) \n",
    "x_train = x_data[:k] \n",
    "x_val = x_data[k:] \n",
    "y_train = y_data_augmented[:k,:] \n",
    "y_val = y_data_augmented[k:,:] \n",
    "\n",
    "len(x_train), len(x_val), y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in parameters and labels dictionary  \n",
    "train_label_idx = 0 \n",
    "for filename in x_train:  \n",
    "    partition['train'].append(filename) \n",
    "    labels[filename] = y_train[train_label_idx]\n",
    "    train_label_idx += 1 \n",
    "\n",
    "val_label_idx = 0 \n",
    "for filename in x_val:  \n",
    "    partition['validation'].append(filename) \n",
    "    labels[filename] = y_val[val_label_idx] \n",
    "    val_label_idx += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and validation generators \n",
    "training_generator = DataGenerator(partition['train'], labels, **params)\n",
    "validation_generator = DataGenerator(partition['validation'], labels, **params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_layer, n_filters, kernel): \n",
    "    conv1 = Conv2D(n_filters, kernel, activation = 'selu', kernel_initializer = 'lecun_normal', padding = 'same')(input_layer)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv2 = Conv2D(n_filters, kernel, activation = 'selu', kernel_initializer = 'lecun_normal', padding = 'same')(conv1)\n",
    "    conv1 = Add()([conv1, conv2])   \n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    maxpool = MaxPooling2D((2,2))(conv1) \n",
    "    avgpool = AveragePooling2D((2,2))(conv1)\n",
    "    ret = Add()([maxpool,avgpool])\n",
    "    return ret \n",
    "\n",
    "def dense_layer(input_layer, num): \n",
    "    dense = Dense(num, activation = 'selu', kernel_initializer = 'lecun_normal')(input_layer) \n",
    "    dense = BatchNormalization()(dense) \n",
    "    return dense \n",
    "\n",
    "def build_model(): \n",
    "    inputs = Input((98,221,1)) \n",
    "    conv1 = conv2d_block(inputs, 32, 3) \n",
    "    for i in range(3): \n",
    "        conv1 = conv2d_block(conv1, 32, 3) \n",
    "    outputs = Flatten()(conv1)  \n",
    "    for i in range(2):  \n",
    "        outputs = Dense(256, activation = 'selu', kernel_initializer = 'lecun_normal')(outputs)  \n",
    "        outputs = BatchNormalization()(outputs) \n",
    "    outputs = Dense(30, activation = 'softmax')(outputs) \n",
    "    model = Model(inputs = inputs, outputs = outputs) \n",
    "    model.compile(loss=tf.keras.losses.KLDivergence(), optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0813 14:04:53.812673 140428315416384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0813 14:04:53.835539 140428315416384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0813 14:04:53.839539 140428315416384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0813 14:04:53.911444 140428315416384 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3217: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0813 14:04:53.925697 140428315416384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0813 14:04:53.926340 140428315416384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0813 14:04:55.009082 140428315416384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0813 14:04:55.220136 140428315416384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0813 14:04:55.222638 140428315416384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "W0813 14:04:56.090626 140428315416384 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 98, 221, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 98, 221, 32)  320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 98, 221, 32)  128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 98, 221, 32)  9248        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 98, 221, 32)  0           batch_normalization_1[0][0]      \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 98, 221, 32)  128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 49, 110, 32)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 49, 110, 32)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 49, 110, 32)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 49, 110, 32)  9248        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 49, 110, 32)  128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 49, 110, 32)  9248        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 49, 110, 32)  0           batch_normalization_3[0][0]      \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 49, 110, 32)  128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 55, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 24, 55, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 24, 55, 32)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 24, 55, 32)   9248        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 24, 55, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 24, 55, 32)   9248        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 24, 55, 32)   0           batch_normalization_5[0][0]      \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 24, 55, 32)   128         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 27, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 12, 27, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 12, 27, 32)   0           max_pooling2d_3[0][0]            \n",
      "                                                                 average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 12, 27, 32)   9248        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 12, 27, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 12, 27, 32)   9248        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 12, 27, 32)   0           batch_normalization_7[0][0]      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 12, 27, 32)   128         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 13, 32)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 6, 13, 32)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 6, 13, 32)    0           max_pooling2d_4[0][0]            \n",
      "                                                                 average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2496)         0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          639232      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 256)          1024        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 30)           7710        batch_normalization_10[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 780,862\n",
      "Trainable params: 779,326\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1250/1250 [==============================] - 1928s 2s/step - loss: 1.5851 - val_loss: 1.5062\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.50619, saving model to ./storage/cnn_model_augmented/epoch_001_val_1.506.h5\n",
      "Epoch 2/150\n",
      "1250/1250 [==============================] - 2142s 2s/step - loss: 1.3192 - val_loss: 1.3411\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.50619 to 1.34110, saving model to ./storage/cnn_model_augmented/epoch_002_val_1.341.h5\n",
      "Epoch 3/150\n",
      "1250/1250 [==============================] - 1766s 1s/step - loss: 1.2169 - val_loss: 1.2756\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.34110 to 1.27558, saving model to ./storage/cnn_model_augmented/epoch_003_val_1.276.h5\n",
      "Epoch 4/150\n",
      "1250/1250 [==============================] - 1868s 1s/step - loss: 1.1491 - val_loss: 1.2616\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.27558 to 1.26158, saving model to ./storage/cnn_model_augmented/epoch_004_val_1.262.h5\n",
      "Epoch 5/150\n",
      "1250/1250 [==============================] - 1880s 2s/step - loss: 1.0981 - val_loss: 1.2222\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.26158 to 1.22224, saving model to ./storage/cnn_model_augmented/epoch_005_val_1.222.h5\n",
      "Epoch 6/150\n",
      "1250/1250 [==============================] - 1860s 1s/step - loss: 1.0570 - val_loss: 1.2142\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.22224 to 1.21424, saving model to ./storage/cnn_model_augmented/epoch_006_val_1.214.h5\n",
      "Epoch 7/150\n",
      "1250/1250 [==============================] - 1805s 1s/step - loss: 1.0228 - val_loss: 1.2058\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.21424 to 1.20576, saving model to ./storage/cnn_model_augmented/epoch_007_val_1.206.h5\n",
      "Epoch 8/150\n",
      "1250/1250 [==============================] - 1790s 1s/step - loss: 0.9936 - val_loss: 1.2408\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 1.20576\n",
      "Epoch 9/150\n",
      "1250/1250 [==============================] - 1794s 1s/step - loss: 0.9685 - val_loss: 1.2108\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.20576\n",
      "Epoch 10/150\n",
      "1250/1250 [==============================] - 1857s 1s/step - loss: 0.9462 - val_loss: 1.2181\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 1.20576\n",
      "Epoch 11/150\n",
      "1250/1250 [==============================] - 2052s 2s/step - loss: 0.9259 - val_loss: 1.2432\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.20576\n",
      "Epoch 12/150\n",
      "1250/1250 [==============================] - 1849s 1s/step - loss: 0.9086 - val_loss: 1.2286\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 1.20576\n",
      "Epoch 13/150\n",
      "1250/1250 [==============================] - 1933s 2s/step - loss: 0.8915 - val_loss: 1.2428\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 1.20576\n",
      "Epoch 14/150\n",
      "1250/1250 [==============================] - 1953s 2s/step - loss: 0.8768 - val_loss: 1.2514\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.20576\n",
      "Epoch 15/150\n",
      "1250/1250 [==============================] - 1917s 2s/step - loss: 0.8639 - val_loss: 1.2595\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.20576\n",
      "Epoch 16/150\n",
      "1250/1250 [==============================] - 1873s 1s/step - loss: 0.8505 - val_loss: 1.2729\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.20576\n",
      "Epoch 17/150\n",
      "1250/1250 [==============================] - 1801s 1s/step - loss: 0.8386 - val_loss: 1.2694\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.20576\n"
     ]
    }
   ],
   "source": [
    "model_path = './storage/cnn_model_augmented/epoch_{epoch:03d}_val_{val_loss:.3f}.h5' \n",
    "checkpoint = ModelCheckpoint(filepath=model_path,monitor='val_loss',verbose=1,save_best_only=True)\n",
    "early_stopping = EarlyStopping(monitor='val_loss',patience=10)\n",
    "history = model.fit_generator(generator = training_generator, validation_data = validation_generator, epochs = 150, callbacks=[checkpoint, early_stopping])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.epoch, history.history['loss'],'-o',label='training_loss')\n",
    "plt.plot(history.epoch, history.history['val_loss'], '-o',label='validation_loss')\n",
    "plt.legend() \n",
    "plt.xlim(left=0)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8892/10000 [05:04<00:38, 28.60it/s]"
     ]
    }
   ],
   "source": [
    "x_test = [os.path.join('./storage/test_files/test/',file) for file in os.listdir('./storage/test_files/test/')] \n",
    "x_test.sort()\n",
    "out = [] \n",
    "for file in tqdm(x_test): \n",
    "    sample, sample_rate = librosa.load(file) \n",
    "    freqs, times, spectrogram = log_specgram(sample, sample_rate) \n",
    "    mean = np.mean(spectrogram, axis=0) \n",
    "    std = np.std(spectrogram, axis = 0)\n",
    "    spectrogram = (spectrogram - mean)/std  \n",
    "    spectrogram = spectrogram.reshape((spectrogram.shape[0],spectrogram.shape[1],1)) \n",
    "    out.append(spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 98, 221, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = np.asarray(out)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 98, 221, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 98, 221, 32)  320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 98, 221, 32)  128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 98, 221, 32)  9248        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 98, 221, 32)  0           batch_normalization_1[0][0]      \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 98, 221, 32)  128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 49, 110, 32)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 49, 110, 32)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 49, 110, 32)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 49, 110, 32)  9248        add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 49, 110, 32)  128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 49, 110, 32)  9248        batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 49, 110, 32)  0           batch_normalization_3[0][0]      \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 49, 110, 32)  128         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 24, 55, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 24, 55, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 24, 55, 32)   0           max_pooling2d_2[0][0]            \n",
      "                                                                 average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 24, 55, 32)   9248        add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 24, 55, 32)   128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 24, 55, 32)   9248        batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 24, 55, 32)   0           batch_normalization_5[0][0]      \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 24, 55, 32)   128         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 27, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 12, 27, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 12, 27, 32)   0           max_pooling2d_3[0][0]            \n",
      "                                                                 average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 12, 27, 32)   9248        add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 12, 27, 32)   128         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 12, 27, 32)   9248        batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 12, 27, 32)   0           batch_normalization_7[0][0]      \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 12, 27, 32)   128         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 6, 13, 32)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 6, 13, 32)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 6, 13, 32)    0           max_pooling2d_4[0][0]            \n",
      "                                                                 average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2496)         0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          639232      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 256)          1024        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 30)           7710        batch_normalization_10[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 780,862\n",
      "Trainable params: 779,326\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model = load_model('./storage/cnn_model_augmented/epoch_007_val_1.206.h5',compile=False)\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.compile(loss=tf.keras.losses.KLDivergence(), optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bed</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>down</th>\n",
       "      <th>eight</th>\n",
       "      <th>five</th>\n",
       "      <th>four</th>\n",
       "      <th>go</th>\n",
       "      <th>happy</th>\n",
       "      <th>...</th>\n",
       "      <th>sheila</th>\n",
       "      <th>six</th>\n",
       "      <th>stop</th>\n",
       "      <th>three</th>\n",
       "      <th>tree</th>\n",
       "      <th>two</th>\n",
       "      <th>up</th>\n",
       "      <th>wow</th>\n",
       "      <th>yes</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010107</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.019117</td>\n",
       "      <td>0.273678</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.009575</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.117688</td>\n",
       "      <td>9.266782e-02</td>\n",
       "      <td>0.067794</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.011425</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.289810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013202</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.015679</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.051553</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.016925</td>\n",
       "      <td>2.004952e-01</td>\n",
       "      <td>0.149615</td>\n",
       "      <td>0.064215</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.021857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009404</td>\n",
       "      <td>0.005459</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.004208</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.045382</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.152729</td>\n",
       "      <td>0.349702</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>5.646699e-04</td>\n",
       "      <td>0.144045</td>\n",
       "      <td>0.019445</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.068699</td>\n",
       "      <td>0.015118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007604</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.158001</td>\n",
       "      <td>0.355563</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008582</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.047959</td>\n",
       "      <td>2.530133e-01</td>\n",
       "      <td>0.045576</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.002618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009465</td>\n",
       "      <td>0.011006</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.022846</td>\n",
       "      <td>0.085229</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.021614</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.007739</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>6.961866e-07</td>\n",
       "      <td>0.000820</td>\n",
       "      <td>0.007682</td>\n",
       "      <td>0.011228</td>\n",
       "      <td>0.012172</td>\n",
       "      <td>0.003139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         bed      bird       cat       dog      down     eight      five  \\\n",
       "id                                                                         \n",
       "0   0.010107  0.000804  0.000181  0.000784  0.019117  0.273678  0.000241   \n",
       "1   0.013202  0.002525  0.000179  0.000028  0.000059  0.001542  0.015679   \n",
       "2   0.009404  0.005459  0.000109  0.001863  0.001490  0.003802  0.004208   \n",
       "3   0.007604  0.000786  0.000196  0.000137  0.000598  0.002164  0.158001   \n",
       "4   0.009465  0.011006  0.000717  0.022846  0.085229  0.000177  0.021614   \n",
       "\n",
       "        four        go     happy  ...    sheila       six      stop     three  \\\n",
       "id                                ...                                           \n",
       "0   0.009575  0.021891  0.000631  ...  0.004374  0.001475  0.000381  0.117688   \n",
       "1   0.001082  0.000666  0.004037  ...  0.003698  0.051553  0.000551  0.016925   \n",
       "2   0.000139  0.045382  0.003444  ...  0.003199  0.152729  0.349702  0.004177   \n",
       "3   0.355563  0.001797  0.002413  ...  0.008582  0.001927  0.000478  0.047959   \n",
       "4   0.003737  0.007739  0.005233  ...  0.000048  0.004187  0.005472  0.000456   \n",
       "\n",
       "            tree       two        up       wow       yes      zero  \n",
       "id                                                                  \n",
       "0   9.266782e-02  0.067794  0.001654  0.011425  0.000093  0.289810  \n",
       "1   2.004952e-01  0.149615  0.064215  0.000058  0.000502  0.021857  \n",
       "2   5.646699e-04  0.144045  0.019445  0.000072  0.068699  0.015118  \n",
       "3   2.530133e-01  0.045576  0.001392  0.001597  0.000769  0.002618  \n",
       "4   6.961866e-07  0.000820  0.007682  0.011228  0.012172  0.003139  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = best_model.predict(out)\n",
    "submission = pd.read_csv('./storage/submission.csv',index_col=0)\n",
    "submission.loc[:,:] = y_pred \n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output \n",
    "submission.to_csv('./storage/spectrogram_cnn_augmented.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
